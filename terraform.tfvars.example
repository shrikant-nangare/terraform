# Copy this file to terraform.tfvars and customize as needed

# Basic Configuration
aws_region = "us-east-1"
project_name = "my-project"
vpc_cidr = "10.0.0.0/16"
enable_nat_gateway = true

# VPC Subnet Configuration
# Number of public and private subnets to create (one per availability zone)
# Default: 3 (creates 3 public and 3 private subnets across 3 AZs)
vpc_subnet_count = 3

# EC2 Instance Configuration
# Creates 1 instance in public subnet and 1 instance in private subnet
instance_type = "t3.micro"
key_pair_name = "your-key-pair-name"  # Required: Replace with your actual key pair name
ssh_allowed_cidr = "0.0.0.0/0"  # Restrict this to your IP for better security
# user_data = ""  # Optional: Add user data script if needed

# Auto Scaling Group Configuration
# ASG scales based on CPU utilization (target: 60%)
asg_instance_type = "t3.micro"
asg_min_size = 1
asg_max_size = 5
asg_desired_capacity = 1
asg_cpu_target = 60  # CPU utilization target percentage for auto scaling

# EKS Cluster Configuration
# Set eks_cluster_name to "" (empty string) to disable EKS entirely
eks_cluster_name = ""  # Set to cluster name to enable, or "" to disable
eks_kubernetes_version = "1.32"  # AWS EKS standard support: 1.32, 1.33, 1.34. Extended support: 1.29, 1.30, 1.31
eks_node_instance_type = "t3.small"

# EKS Node Group Scaling Configuration
eks_node_desired_size = 2  # Desired number of nodes in each node group
eks_node_min_size = 1      # Minimum number of nodes in each node group
eks_node_max_size = 3      # Maximum number of nodes in each node group

# EKS IAM Roles Configuration
# Option 1: Use Permitted Role Names (Recommended if allowed)
# Terraform will create eksClusterRole and AmazonEKSNodeRole automatically
use_eks_permitted_roles = true
eks_cluster_role_arn = ""  # Leave empty when use_eks_permitted_roles = true
eks_node_group_role_arn = ""  # Leave empty when use_eks_permitted_roles = true

# Option 2: Use Existing Roles
# If you don't have permission to create roles, use existing role ARNs
# use_eks_permitted_roles = false
# eks_cluster_role_arn = "arn:aws:iam::ACCOUNT_ID:role/eksClusterRole"
# eks_node_group_role_arn = "arn:aws:iam::ACCOUNT_ID:role/AmazonEKSNodeRole"
#
# To find existing roles:
# aws iam list-roles --query 'Roles[?contains(RoleName, `eks`) || contains(RoleName, `EKS`)].{RoleName:RoleName, Arn:Arn}' --output table

# EKS Fargate Configuration (Recommended for resource-constrained environments)
# When enabled, managed node groups are NOT created
# Fargate is better suited for strict resource limits (256m CPU, 512Mi memory per pod)
# Set to true to use Fargate instead of managed node groups
eks_enable_fargate = false  # Set to true to use Fargate profiles
eks_fargate_profile_namespaces = ["default", "kube-system"]  # Namespaces to run on Fargate
# eks_fargate_pod_execution_role_arn = ""  # Leave empty to let Terraform create the role

# Tags (Optional)
# tags = {
#   Environment = "development"
#   Team        = "platform"
#   ManagedBy   = "terraform"
# }
